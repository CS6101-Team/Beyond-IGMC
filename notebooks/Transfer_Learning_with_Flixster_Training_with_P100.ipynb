{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Flixster Training with P100.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRCxMwkvwoSQ",
        "outputId": "7ed50094-d15f-44de-d500-37cf5b58d58e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Apr  4 08:30:42 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhmKH1TQgMFq",
        "outputId": "e0ec2678-c357-497a-c84a-497db95f0e73"
      },
      "source": [
        "!pip install hdf5storage"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting hdf5storage\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/c2/754164946f40afc64421777340fb2372c0483e4c68a7ac5cffde85beaf1d/hdf5storage-0.1.17-py2.py3-none-any.whl (52kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 20.0MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 11.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 30kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy; python_version >= \"3.4\" in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (1.19.5)\n",
            "Requirement already satisfied: h5py>=2.1; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from hdf5storage) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py>=2.1; python_version >= \"3.3\"->hdf5storage) (1.15.0)\n",
            "Installing collected packages: hdf5storage\n",
            "Successfully installed hdf5storage-0.1.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1RKNFk8gdPV",
        "outputId": "d4d83ea8-1675-483b-c7f6-173d0a386508"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBb-0QdQgMIg"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import h5py\n",
        "import hdf5storage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecrcl0sQkBx4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj8n_2f4gMLV",
        "outputId": "e251f13a-0ec6-4ad5-a757-3aafd63118ca"
      },
      "source": [
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Digital_Music_5.json.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-24 11:56:39--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Digital_Music_5.json.gz\n",
            "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
            "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19408584 (19M) [application/octet-stream]\n",
            "Saving to: ‘Digital_Music_5.json.gz’\n",
            "\n",
            "Digital_Music_5.jso 100%[===================>]  18.51M  10.5MB/s    in 1.8s    \n",
            "\n",
            "2021-03-24 11:56:41 (10.5 MB/s) - ‘Digital_Music_5.json.gz’ saved [19408584/19408584]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2VscdFkgMN2"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "\n",
        "def parse(path):\n",
        "  g = gzip.open(path, 'rb')\n",
        "  for l in g:\n",
        "    yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "  i = 0\n",
        "  df = {}\n",
        "  for d in parse(path):\n",
        "    df[i] = d\n",
        "    i += 1\n",
        "  return pd.DataFrame.from_dict(df, orient='index')\n",
        "\n",
        "df = getDF('/content/Digital_Music_5.json.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8VG3RtYgMQ7"
      },
      "source": [
        "new_df = df.drop(labels = ['style', 'verified', 'reviewTime', 'reviewerName',\n",
        "                  'reviewText', 'summary', 'vote', 'image'], axis=1)\n",
        "new_df = new_df.rename(columns = {'overall': 'rating', 'reviewerID' : 'user', 'asin': 'item', 'unixReviewTime' : 'timestamp'})\n",
        "\n",
        "data = new_df\n",
        "\n",
        "data = data.drop(['timestamp'], axis = 1).groupby(['item', 'user']).aggregate(np.mean).reset_index()\n",
        "\n",
        "data['rating'] = [int(np.round(x)) for x in data['rating']]\n",
        "\n",
        "for category in ['item', 'user']:\n",
        "  lst = list(set(data[category]))\n",
        "  lst.sort()\n",
        "  lst = [tup[::-1] for tup in list(enumerate(lst))]\n",
        "  curr_dict = dict(lst)\n",
        "  data[category] = [curr_dict[id] for id in data[category].values]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKRtwXkqneu8"
      },
      "source": [
        "matrix_df = data.pivot_table(index = 'user', columns = 'item', values = 'rating').fillna(0).astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_TEYKyTnjb7"
      },
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "threshold = 20 # testing split percentage (example)\n",
        "# train_test_split\n",
        "matrix = matrix_df.values\n",
        "Otraining_matrix = matrix.copy()\n",
        "Otest_matrix = matrix.copy()\n",
        "\n",
        "for i in range(matrix.shape[0]):\n",
        "  for j in range(matrix.shape[1]):\n",
        "    if matrix[i][j] > 0:\n",
        "      random_int = np.random.randint(0, 100)\n",
        "\n",
        "      if random_int < threshold:\n",
        "        Otest_matrix[i][j] = 1\n",
        "        Otraining_matrix[i][j] = 0\n",
        "\n",
        "      else:\n",
        "        Otraining_matrix[i][j] = 1\n",
        "        Otest_matrix[i][j] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lhq3lODDKtIK",
        "outputId": "e1b7210f-f4ee-4843-adf8-8bca1b9180ad"
      },
      "source": [
        "%cd ../.."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/IGMC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_TWb890gMTY"
      },
      "source": [
        "\n",
        "matfiledata = {} # make a dictionary to store the MAT data in\n",
        "matfiledata[u'variable1'] = np.zeros(100) # *** u prefix for variable name = unicode format, no issues thru Python 3.5; advise keeping u prefix indicator format based on feedback despite docs ***\n",
        "matfiledata[u'variable2'] = np.ones(300)\n",
        "\n",
        "mdic = {u\"M\": matrix, u\"Otraining\": Otraining_matrix, u\"Otest\": Otest_matrix}\n",
        "# sio.savemat('/content/amazon_vg.mat', mdic)\n",
        "hdf5storage.write(mdic, '.', 'train_test_dataset.mat', matlab_compatible=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CUmTmbyw3-S",
        "outputId": "939b7c94-39b6-4ab3-82d9-e65632612968"
      },
      "source": [
        "# git clone\n",
        "\n",
        "!git clone -b transfer_learning --single-branch https://github.com/CS6101-Team/IGMC.git\n",
        "\n",
        "import os\n",
        "# os.getcwd()\n",
        "\n",
        "# Change Directory\n",
        "\n",
        "%cd /content/IGMC\n",
        "\n",
        "# install packages\n",
        "# torch 1.4.0\n",
        "\n",
        "!pip install torch==1.4.0 torchvision==0.5.0\n",
        "\n",
        "# torch-geometric 1.4.2\n",
        "\n",
        "!pip install --no-index torch-scatter -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
        "!pip install --no-index torch-sparse -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
        "!pip install --no-index torch-cluster -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
        "!pip install --no-index torch-spline-conv -f https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
        "!pip install torch-geometric==1.4.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IGMC'...\n",
            "remote: Enumerating objects: 344, done.\u001b[K\n",
            "remote: Counting objects: 100% (344/344), done.\u001b[K\n",
            "remote: Compressing objects: 100% (289/289), done.\u001b[K\n",
            "remote: Total 596 (delta 88), reused 286 (delta 44), pack-reused 252\u001b[K\n",
            "Receiving objects: 100% (596/596), 89.28 MiB | 20.36 MiB/s, done.\n",
            "Resolving deltas: 100% (223/223), done.\n",
            "/content/IGMC\n",
            "Collecting torch==1.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
            "\u001b[K     |████████████████████████████████| 753.4MB 21kB/s \n",
            "\u001b[?25hCollecting torchvision==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/32/cb0e4c43cd717da50258887b088471568990b5a749784c465a8a1962e021/torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0MB 69.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.5.0) (1.19.5)\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.4.0 torchvision-0.5.0\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
            "Collecting torch-scatter\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.4.0%2Bcu101/torch_scatter-2.0.4-cp37-cp37m-linux_x86_64.whl (10.6MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6MB 12.1MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.4\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
            "Collecting torch-sparse\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.4.0%2Bcu101/torch_sparse-0.6.1-cp37-cp37m-linux_x86_64.whl (15.2MB)\n",
            "\u001b[K     |████████████████████████████████| 15.2MB 208kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.1\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
            "Collecting torch-cluster\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.4.0%2Bcu101/torch_cluster-1.5.4-cp37-cp37m-linux_x86_64.whl (14.5MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5MB 239kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-cluster) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-cluster) (1.19.5)\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.4\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.4.0+cu101.html\n",
            "Collecting torch-spline-conv\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.4.0%2Bcu101/torch_spline_conv-1.2.0-cp37-cp37m-linux_x86_64.whl (5.1MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1MB 13.9MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.0\n",
            "Collecting torch-geometric==1.4.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/b3/0516919a575a1a0a862bab1decfcfb5285ced09e9ffae6442af3b5981301/torch_geometric-1.4.2.tar.gz (139kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 13.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.2) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.2) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.2) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.2) (2.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.2) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.2) (0.16.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.2) (0.51.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.2) (2.23.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/03/6e/cb64d254c6d474a7cf636a7c7e318ab7c4ec8e4082cabaa2aab81f9b6a65/plyfile-0.7.3-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.2) (1.1.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 23.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.2) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric==1.4.2) (0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric==1.4.2) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric==1.4.2) (1.0.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric==1.4.2) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric==1.4.2) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric==1.4.2) (3.2.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->torch-geometric==1.4.2) (7.1.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric==1.4.2) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric==1.4.2) (54.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.4.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.4.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.4.2) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric==1.4.2) (2020.12.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==1.4.2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric==1.4.2) (2.8.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==1.4.2) (2.4.7)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric==1.4.2) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric==1.4.2) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric==1.4.2) (0.10.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.4.2-cp37-none-any.whl size=224447 sha256=6d40b2fd02a2e8f069a457fd13919cc4a4a591f4f230e81abca6f60efe56edf1\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/9d/a3/2de0c1fb436ec76e2942b4216b820589d40bc48395995c3076\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: plyfile, isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 plyfile-0.7.3 rdflib-5.0.0 torch-geometric-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_crHQNwGxIsN"
      },
      "source": [
        "# Training with Flixster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYzW4gBmda8s",
        "outputId": "d3a3ac33-71be-4311-8d71-9bdbc6bf113b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cm-DqAqxxzH"
      },
      "source": [
        "4 digit code:  \n",
        "1st digit: 1-hop or 2-hop (1 or 2)   \n",
        "2nd digit: Aggregation layer  \n",
        "c - concatentation  \n",
        "m - max pooling  \n",
        "l - lstm-attention  \n",
        "3rd digit: Use of graph norm (0 or 1).  \n",
        "4th digit: Use of graph sage (0 or 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjnyVqyNyaFK"
      },
      "source": [
        "from IPython.display import Javascript"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9x3t5JMkfexZ",
        "outputId": "163914da-8009-4fa8-8725-b6ab4612cbd8"
      },
      "source": [
        "!du -sk raw_data/amazon_fashion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28\traw_data/amazon_fashion\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0C0icCkx0PS",
        "outputId": "c58838eb-47f0-4ab4-9c95-4668ea7592ca"
      },
      "source": [
        "!cp /content/drive/Shareddrives/Unlimited\\ Google\\ Drive\\ 3/Files/amazon_fashion.mat /content/IGMC/raw_data/amazon_fashion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: error reading '/content/drive/Shareddrives/Unlimited Google Drive 3/Files/amazon_fashion.mat': Input/output error\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04G1AlFfx7Fg",
        "outputId": "844c1ede-e4f1-489d-cb60-960541782426"
      },
      "source": [
        "!git clone -b master --single-branch https://github.com/CS6101-Team/IGMC.git\n",
        "\n",
        "%cd /content/IGMC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'IGMC'...\n",
            "remote: Enumerating objects: 317, done.\u001b[K\n",
            "remote: Counting objects: 100% (317/317), done.\u001b[K\n",
            "remote: Compressing objects: 100% (271/271), done.\u001b[K\n",
            "remote: Total 569 (delta 76), reused 264 (delta 35), pack-reused 252\u001b[K\n",
            "Receiving objects: 100% (569/569), 75.13 MiB | 25.63 MiB/s, done.\n",
            "Resolving deltas: 100% (211/211), done.\n",
            "/content/IGMC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7YiQYCzxq7O"
      },
      "source": [
        "## t2c00 (Base IGMC) Amazon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "wg9_mASqxvLt",
        "outputId": "674a9866-6e38-41a7-840e-b4117b358b6c"
      },
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "!python Main.py --data-name ml_100k --epochs 40 --fname t3c00 --testing --dynamic-train --ensemble --model-type IGMC"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Namespace(ARR=0.001, adj_dropout=0.2, batch_size=50, continue_from=None, data_appendix='', data_name='ml_100k', data_seed=1234, debug=False, dynamic_test=False, dynamic_train=True, dynamic_val=False, ensemble=True, epochs=40, fname='t3c00', force_undirected=False, gconv_type='GCNConv', hop=1, keep_old=False, lr=0.001, lr_decay_factor=0.1, lr_decay_step_size=50, max_nodes_per_hop=10000, max_test_num=None, max_train_num=None, max_val_num=None, model_type='IGMC', multiply_by=1, no_train=False, num_relations=5, ratio=1.0, reprocess=False, sample_ratio=1.0, save_appendix='', save_interval=10, seed=1, standard_rating=False, test_freq=1, testing=True, transfer='', use_features=False, use_graphnorm=False, visualize=False)\n",
            "Command line input: python Main.py --data-name ml_100k --epochs 40 --fname t3c00 --testing --dynamic-train --ensemble --model-type IGMC\n",
            " is saved.\n",
            "Using official MovieLens split u1.base/u1.test with 20% validation...\n",
            "Downloading ml_100k dataset\n",
            "User features shape: (943, 23)\n",
            "Item features shape: (1682, 18)\n",
            "All ratings are:\n",
            "[1. 2. 3. 4. 5.]\n",
            "#train: 80000, #val: 16000, #test: 20000\n",
            "Processing...\n",
            "Enclosing subgraph extraction begins...\n",
            " 94% 15/16 [00:14<00:00,  1.04it/s]\n",
            "Time elapsed for subgraph extraction: 14.399215459823608s\n",
            "Transforming to pytorch_geometric graphs...\n",
            "100% 20000/20000 [00:03<00:00, 5124.57it/s]\n",
            "Time elapsed for transforming to pytorch_geometric graphs: 3.903179407119751s\n",
            "tcmalloc: large alloc 2441805824 bytes == 0x556821398000 @  0x7f34bcebcb6b 0x7f34bcedc379 0x7f344edf7b4a 0x7f344edf95fa 0x7f34514ff9fb 0x7f34515135cd 0x7f34515226f7 0x7f3451405170 0x7f34513b94c5 0x7f34513baaa9 0x7f3451171c3e 0x7f3451478f0a 0x7f34513baaa9 0x7f34531d0174 0x7f34513baaa9 0x7f3499ea6330 0x7f3499e09a95 0x556721e0f0e4 0x556721e0ede0 0x556721e836f5 0x556721e1069a 0x556721e7ec9e 0x556721e1069a 0x556721e7ec9e 0x556721e1069a 0x556721e7ec9e 0x556721e7de0d 0x556721e1077a 0x556721e82e50 0x556721e7de0d 0x556721e1077a\n",
            "tcmalloc: large alloc 1220902912 bytes == 0x5568b2ce6000 @  0x7f34bcebcb6b 0x7f34bcedc379 0x7f344edf7b4a 0x7f344edf95fa 0x7f34514ff9fb 0x7f34515135cd 0x7f34515226f7 0x7f3451405170 0x7f34513b94c5 0x7f34513baaa9 0x7f3451171c3e 0x7f3451478f0a 0x7f34513baaa9 0x7f34531d0174 0x7f34513baaa9 0x7f3499ea6330 0x7f3499e09a95 0x556721e0f0e4 0x556721e0ede0 0x556721e836f5 0x556721e1069a 0x556721e7ec9e 0x556721e1069a 0x556721e7ec9e 0x556721e1069a 0x556721e7ec9e 0x556721e7de0d 0x556721e1077a 0x556721e82e50 0x556721e7de0d 0x556721e1077a\n",
            "Done!\n",
            "tcmalloc: large alloc 2441805824 bytes == 0x556821398000 @  0x7f34bcebcb6b 0x7f34bcedc379 0x7f344edf7b4a 0x7f344edf95fa 0x7f34514fdc44 0x7f3499fd0770 0x556721e4ec25 0x556721e0f7f2 0x556721e82d75 0x556721e7de0d 0x556721e1038b 0x556721e0fe99 0x556721f5770d 0x556721ec657b 0x556721e0ef41 0x556721f0099d 0x556721e82fe9 0x556721e7de0d 0x556721d4fe2b 0x556721e801e6 0x556721e7db0e 0x556721e1077a 0x556721e82e50 0x556721e7de0d 0x556721e1102c 0x556721e51d39 0x556721e4ec84 0x556721e0f8e9 0x556721e83ade 0x556721e7db0e 0x556721e7d813\n",
            "Used #train graphs: 80000, #test graphs: 20000\n",
            "Total number of parameters is 55666\n",
            "Epoch 10, train loss 0.907941, test rmse 0.944802:  22% 9/40 [1:29:44<4:38:14, 538.54s/it]Saving model states...\n",
            "Epoch 20, train loss 0.887579, test rmse 0.936687:  48% 19/40 [2:59:28<3:08:23, 538.27s/it]Saving model states...\n",
            "Epoch 30, train loss 0.883244, test rmse 0.941519:  72% 29/40 [4:29:07<1:38:28, 537.15s/it]Saving model states...\n",
            "Epoch 40, train loss 0.880353, test rmse 0.944337:  98% 39/40 [5:58:43<08:57, 537.29s/it]Saving model states...\n",
            "Epoch 40, train loss 0.880353, test rmse 0.944337: 100% 40/40 [5:58:43<00:00, 538.08s/it]\n",
            "Final Test RMSE: 0.944337, Duration: 21523.007557\n",
            "Testing begins...\n",
            "100% 400/400 [00:32<00:00, 12.43it/s]\n",
            "Testing begins...\n",
            "100% 400/400 [00:32<00:00, 12.46it/s]\n",
            "Testing begins...\n",
            "100% 400/400 [00:32<00:00, 12.44it/s]\n",
            "Testing begins...\n",
            "100% 400/400 [00:32<00:00, 12.46it/s]\n",
            "Test Once RMSE: 0.933028, Duration: 128.605096\n",
            "Ensemble test rmse is: 0.933028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzIOoA8rjs-B"
      },
      "source": [
        "!mv /content/IGMC/results/ml_100k_testmode /content/IGMC/results/t3c00"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gne3ZH87kZk"
      },
      "source": [
        "## t2c10 (IGMC with graph norm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "IZTwVFoc4ESz",
        "outputId": "40b7bedc-b12e-47db-a3c5-2c70e53436cd"
      },
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "!python Main.py --data-name amazon_fashion --epochs 40 --testing --ensemble --hop 1 --model-type IGMC --use-graphnorm --fname t2c10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Namespace(ARR=0.001, adj_dropout=0.2, batch_size=50, continue_from=None, data_appendix='', data_name='amazon_fashion', data_seed=1234, debug=False, dynamic_test=False, dynamic_train=False, dynamic_val=False, ensemble=True, epochs=40, fname='t2c10', force_undirected=False, gconv_type='GCNConv', hop='1', keep_old=False, lr=0.001, lr_decay_factor=0.1, lr_decay_step_size=50, max_nodes_per_hop=10000, max_test_num=None, max_train_num=None, max_val_num=None, model_type='IGMC', multiply_by=1, no_train=False, num_relations=5, ratio=1.0, reprocess=False, sample_ratio=1.0, save_appendix='', save_interval=10, seed=1, standard_rating=False, test_freq=1, testing=True, transfer='', use_features=False, use_graphnorm=True, visualize=False)\n",
            "Command line input: python Main.py --data-name amazon_fashion --epochs 40 --testing --ensemble --hop 1 --model-type IGMC --use-graphnorm --fname t2c10\n",
            " is saved.\n",
            "raw_data/amazon_fashion/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x5630ae698000 @  0x7faa0ba201e7 0x7faa090da46e 0x7faa0912ac7b 0x7faa0912b35f 0x7faa091cd103 0x5630a799e0e4 0x5630a799dde0 0x5630a7a126f5 0x5630a7a0cb0e 0x5630a78deeb0 0x7fa9727490a4 0x5630a799fd1d 0x5630a799e2ff 0x5630a79a0f6e 0x7faa0912986c 0x7faa0912ca93 0x7faa0912d0bc 0x7faa0912dcbb 0x7faa0912e07b 0x7faa091cf761 0x5630a799e0e4 0x5630a799dde0 0x5630a7a126f5 0x5630a7a0cb0e 0x5630a799f77a 0x5630a7a11e50 0x5630a799f69a 0x5630a7a0da45 0x5630a7a0ce0d 0x5630a799f77a 0x5630a7a0da45\n",
            "raw_data/amazon_fashion/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x5630ae616000 @  0x7faa0ba201e7 0x7faa090da46e 0x7faa0912ac7b 0x7faa0912b35f 0x7faa091cd103 0x5630a799e0e4 0x5630a799dde0 0x5630a7a126f5 0x5630a7a0cb0e 0x5630a78deeb0 0x7fa9727490a4 0x5630a799fd1d 0x5630a799e2ff 0x5630a79a0f6e 0x7faa0912986c 0x7faa0912ca93 0x7faa0912d0bc 0x7faa0912dcbb 0x7faa0912e07b 0x7faa091cf761 0x5630a799e0e4 0x5630a799dde0 0x5630a7a126f5 0x5630a7a0cb0e 0x5630a799f77a 0x5630a7a11e50 0x5630a799f69a 0x5630a7a0da45 0x5630a7a0ce0d 0x5630a799f77a 0x5630a7a0da45\n",
            "raw_data/amazon_fashion/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x5630ae616000 @  0x7faa0ba201e7 0x7faa090da46e 0x7faa0912ac7b 0x7faa0912b35f 0x7faa091cd103 0x5630a799e0e4 0x5630a799dde0 0x5630a7a126f5 0x5630a7a0cb0e 0x5630a78deeb0 0x7fa9727490a4 0x5630a799fd1d 0x5630a799e2ff 0x5630a79a0f6e 0x7faa0912986c 0x7faa0912ca93 0x7faa0912d0bc 0x7faa0912dcbb 0x7faa0912e07b 0x7faa091cf761 0x5630a799e0e4 0x5630a799dde0 0x5630a7a126f5 0x5630a7a0cb0e 0x5630a799f77a 0x5630a7a11e50 0x5630a799f69a 0x5630a7a0da45 0x5630a7a0ce0d 0x5630a799f77a 0x5630a7a0da45\n",
            "number of users =  16566\n",
            "number of item =  11797\n",
            "All ratings are:\n",
            "[1. 2. 3. 4. 5.]\n",
            "#train: 116224, #val: 23245, #test: 29068\n",
            "Used #train graphs: 116224, #test graphs: 29068\n",
            "Total number of parameters is 56050\n",
            "Epoch 1, batch loss: 0.6035417318344116: 100% 2325/2325 [01:09<00:00, 33.37it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.75it/s]\n",
            "Epoch 1, train loss 0.724413, test rmse 0.584798\n",
            "Epoch 2, batch loss: 0.21059845387935638: 100% 2325/2325 [01:09<00:00, 33.37it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 78.78it/s]\n",
            "Epoch 2, train loss 0.566024, test rmse 0.572430\n",
            "Epoch 3, batch loss: 0.47284337878227234: 100% 2325/2325 [01:09<00:00, 33.41it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.75it/s]\n",
            "Epoch 3, train loss 0.484856, test rmse 0.605107\n",
            "Epoch 4, batch loss: 0.8759206533432007: 100% 2325/2325 [01:10<00:00, 33.11it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.67it/s]\n",
            "Epoch 4, train loss 0.426191, test rmse 0.586904\n",
            "Epoch 5, batch loss: 0.16467110812664032: 100% 2325/2325 [01:09<00:00, 33.38it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.88it/s]\n",
            "Epoch 5, train loss 0.388609, test rmse 0.565606\n",
            "Epoch 6, batch loss: 0.5447478294372559: 100% 2325/2325 [01:09<00:00, 33.65it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 78.80it/s]\n",
            "Epoch 6, train loss 0.365912, test rmse 0.563831\n",
            "Epoch 7, batch loss: 0.10582750290632248: 100% 2325/2325 [01:08<00:00, 33.99it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.44it/s]\n",
            "Epoch 7, train loss 0.353089, test rmse 0.567069\n",
            "Epoch 8, batch loss: 0.5077109336853027: 100% 2325/2325 [01:09<00:00, 33.39it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.22it/s]\n",
            "Epoch 8, train loss 0.342104, test rmse 0.569228\n",
            "Epoch 9, batch loss: 0.1310569941997528: 100% 2325/2325 [01:08<00:00, 33.81it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.78it/s]\n",
            "Epoch 9, train loss 0.337580, test rmse 0.564945\n",
            "Epoch 10, batch loss: 0.09273656457662582: 100% 2325/2325 [01:09<00:00, 33.54it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.99it/s]\n",
            "Epoch 10, train loss 0.335913, test rmse 0.571794\n",
            "Saving model states...\n",
            "Epoch 11, batch loss: 0.14092418551445007: 100% 2325/2325 [01:08<00:00, 33.92it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.33it/s]\n",
            "Epoch 11, train loss 0.333444, test rmse 0.573262\n",
            "Epoch 12, batch loss: 0.09725160896778107: 100% 2325/2325 [01:08<00:00, 33.85it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.14it/s]\n",
            "Epoch 12, train loss 0.331414, test rmse 0.563897\n",
            "Epoch 13, batch loss: 0.4207320809364319: 100% 2325/2325 [01:09<00:00, 33.53it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.16it/s]\n",
            "Epoch 13, train loss 0.333725, test rmse 0.567933\n",
            "Epoch 14, batch loss: 0.34360480308532715: 100% 2325/2325 [01:09<00:00, 33.41it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.42it/s]\n",
            "Epoch 14, train loss 0.333262, test rmse 0.565699\n",
            "Epoch 15, batch loss: 0.7988128066062927: 100% 2325/2325 [01:09<00:00, 33.68it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.35it/s]\n",
            "Epoch 15, train loss 0.333387, test rmse 0.559940\n",
            "Epoch 16, batch loss: 0.08188427984714508: 100% 2325/2325 [01:08<00:00, 33.90it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 78.63it/s]\n",
            "Epoch 16, train loss 0.331477, test rmse 0.564167\n",
            "Epoch 17, batch loss: 0.21286579966545105: 100% 2325/2325 [01:07<00:00, 34.30it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.23it/s]\n",
            "Epoch 17, train loss 0.329977, test rmse 0.564359\n",
            "Epoch 18, batch loss: 0.21217358112335205: 100% 2325/2325 [01:08<00:00, 33.72it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.95it/s]\n",
            "Epoch 18, train loss 0.331446, test rmse 0.560814\n",
            "Epoch 19, batch loss: 0.5455121994018555: 100% 2325/2325 [01:08<00:00, 33.88it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.18it/s]\n",
            "Epoch 19, train loss 0.329634, test rmse 0.561589\n",
            "Epoch 20, batch loss: 0.43748611211776733: 100% 2325/2325 [01:07<00:00, 34.33it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.47it/s]\n",
            "Epoch 20, train loss 0.328852, test rmse 0.562135\n",
            "Saving model states...\n",
            "Epoch 21, batch loss: 0.1174849420785904: 100% 2325/2325 [01:08<00:00, 33.86it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.93it/s]\n",
            "Epoch 21, train loss 0.329654, test rmse 0.560546\n",
            "Epoch 22, batch loss: 0.25062504410743713: 100% 2325/2325 [01:08<00:00, 33.86it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.33it/s]\n",
            "Epoch 22, train loss 0.327511, test rmse 0.567940\n",
            "Epoch 23, batch loss: 0.9034316539764404: 100% 2325/2325 [01:07<00:00, 34.52it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.95it/s]\n",
            "Epoch 23, train loss 0.329139, test rmse 0.564008\n",
            "Epoch 24, batch loss: 0.0803636983036995: 100% 2325/2325 [01:07<00:00, 34.41it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.48it/s]\n",
            "Epoch 24, train loss 0.327892, test rmse 0.561967\n",
            "Epoch 25, batch loss: 0.11425673216581345: 100% 2325/2325 [01:08<00:00, 33.92it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.07it/s]\n",
            "Epoch 25, train loss 0.329566, test rmse 0.557895\n",
            "Epoch 26, batch loss: 0.18750497698783875: 100% 2325/2325 [01:08<00:00, 34.11it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.49it/s]\n",
            "Epoch 26, train loss 0.328487, test rmse 0.559724\n",
            "Epoch 27, batch loss: 0.7670775651931763: 100% 2325/2325 [01:07<00:00, 34.27it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 83.99it/s]\n",
            "Epoch 27, train loss 0.326962, test rmse 0.559355\n",
            "Epoch 28, batch loss: 0.346606969833374: 100% 2325/2325 [01:07<00:00, 34.25it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.94it/s]\n",
            "Epoch 28, train loss 0.327638, test rmse 0.560527\n",
            "Epoch 29, batch loss: 0.08121652901172638: 100% 2325/2325 [01:07<00:00, 34.44it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.93it/s]\n",
            "Epoch 29, train loss 0.328811, test rmse 0.577362\n",
            "Epoch 30, batch loss: 0.04645560681819916: 100% 2325/2325 [01:08<00:00, 34.14it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.76it/s]\n",
            "Epoch 30, train loss 0.327862, test rmse 0.566143\n",
            "Saving model states...\n",
            "Epoch 31, batch loss: 0.1074424684047699: 100% 2325/2325 [01:08<00:00, 34.10it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 83.77it/s]\n",
            "Epoch 31, train loss 0.327998, test rmse 0.560087\n",
            "Epoch 32, batch loss: 0.8212186694145203: 100% 2325/2325 [01:08<00:00, 34.06it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.00it/s]\n",
            "Epoch 32, train loss 0.327286, test rmse 0.563115\n",
            "Epoch 33, batch loss: 0.40841031074523926: 100% 2325/2325 [01:07<00:00, 34.48it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 83.13it/s]\n",
            "Epoch 33, train loss 0.326057, test rmse 0.564337\n",
            "Epoch 34, batch loss: 0.636938214302063: 100% 2325/2325 [01:08<00:00, 34.18it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.69it/s]\n",
            "Epoch 34, train loss 0.327074, test rmse 0.561594\n",
            "Epoch 35, batch loss: 0.4825265109539032: 100% 2325/2325 [01:08<00:00, 34.18it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.08it/s]\n",
            "Epoch 35, train loss 0.326489, test rmse 0.560361\n",
            "Epoch 36, batch loss: 0.19831310212612152: 100% 2325/2325 [01:07<00:00, 34.26it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.20it/s]\n",
            "Epoch 36, train loss 0.327303, test rmse 0.561264\n",
            "Epoch 37, batch loss: 0.41088294982910156: 100% 2325/2325 [01:07<00:00, 34.46it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 83.27it/s]\n",
            "Epoch 37, train loss 0.326971, test rmse 0.560361\n",
            "Epoch 38, batch loss: 0.06684212386608124: 100% 2325/2325 [01:07<00:00, 34.41it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.05it/s]\n",
            "Epoch 38, train loss 0.326399, test rmse 0.558467\n",
            "Epoch 39, batch loss: 0.31544584035873413: 100% 2325/2325 [01:08<00:00, 33.88it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.97it/s]\n",
            "Epoch 39, train loss 0.324831, test rmse 0.561334\n",
            "Epoch 40, batch loss: 0.14632411301136017: 100% 2325/2325 [01:08<00:00, 34.11it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 83.34it/s]\n",
            "Epoch 40, train loss 0.326490, test rmse 0.560850\n",
            "Saving model states...\n",
            "Final Test RMSE: 0.560850, Duration: 3027.863798\n",
            "Testing begins...\n",
            "100% 582/582 [00:08<00:00, 65.44it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:08<00:00, 65.47it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:08<00:00, 64.92it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:09<00:00, 63.78it/s]\n",
            "Test Once RMSE: 0.559408, Duration: 35.892405\n",
            "Ensemble test rmse is: 0.559408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5vHCH56y5qs"
      },
      "source": [
        "!python Main.py --data-name ml_100k --epochs 40 --testing --ensemble --hop 1 --model-type IGMC --use-graphnorm --fname t3c10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To8Z3V2QXJJO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlx8omlVW0IA",
        "outputId": "30009ff2-ff41-4ae5-d97c-ebcbc3d4c9f3"
      },
      "source": [
        "!zip -r amazon_music_testmode.zip ./results/amazon_music_testmode/\n",
        "!zip -r ml_100k_testmode.zip ./results/ml_100k_testmode/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating: results/amazon_music_testmode/ (stored 0%)\n",
            "updating: results/amazon_music_testmode/t3c10-tabular_results.csv (deflated 63%)\n",
            "updating: results/amazon_music_testmode/t3m10-tabular_results.csv (deflated 63%)\n",
            "updating: results/amazon_music_testmode/cmd_input.txt (deflated 67%)\n",
            "updating: results/amazon_music_testmode/t3c10-log.csv (deflated 5%)\n",
            "updating: results/amazon_music_testmode/t3m10-log.csv (deflated 6%)\n",
            "updating: results/amazon_music_testmode/t3c00-tabular_results.csv (deflated 63%)\n",
            "updating: results/amazon_music_testmode/t3c00-log.csv (deflated 5%)\n",
            "  adding: results/ml_100k_testmode/ (stored 0%)\n",
            "  adding: results/ml_100k_testmode/t2c00-tabular_results.csv (deflated 64%)\n",
            "  adding: results/ml_100k_testmode/t2c00-log.csv (deflated 5%)\n",
            "  adding: results/ml_100k_testmode/cmd_input.txt (deflated 79%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKPWeJMK-PTo"
      },
      "source": [
        "## 1m00 (IGMC with Max Pooling)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "V31l4En9-ZA3",
        "outputId": "cb4cea07-4023-442d-85f8-27ec1f11486c"
      },
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "!python Main.py --data-name flixster --epochs 40 --testing --ensemble --model-type MaxPoolIGMC --fname 1m00 --hop 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Namespace(ARR=0.001, adj_dropout=0.2, batch_size=50, continue_from=None, data_appendix='', data_name='flixster', data_seed=1234, debug=False, dynamic_test=False, dynamic_train=False, dynamic_val=False, ensemble=True, epochs=40, fname='1m00', force_undirected=False, gconv_type='GCNConv', hop='2', keep_old=False, lr=0.001, lr_decay_factor=0.1, lr_decay_step_size=50, max_nodes_per_hop=10000, max_test_num=None, max_train_num=None, max_val_num=None, model_type='MaxPoolIGMC', multiply_by=1, no_train=False, num_relations=5, ratio=1.0, reprocess=False, sample_ratio=1.0, save_appendix='', save_interval=10, seed=1, standard_rating=False, test_freq=1, testing=True, transfer='', use_features=False, use_graphnorm=False, visualize=False)\n",
            "Command line input: python Main.py --data-name flixster --epochs 40 --testing --ensemble --model-type MaxPoolIGMC --fname 1m00 --hop 2\n",
            " is saved.\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "number of users =  2341\n",
            "number of item =  2956\n",
            "User features shape: (3000, 3000)\n",
            "Item features shape: (3000, 3000)\n",
            "All ratings are:\n",
            "[0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5. ]\n",
            "#train: 23556, #val: 4712, #test: 2617\n",
            "Processing...\n",
            "Enclosing subgraph extraction begins...\n",
            "100% 16/16 [00:02<00:00,  8.24it/s]multiprocessing.pool.RemoteTraceback: \n",
            "\"\"\"\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
            "    return list(itertools.starmap(args[0], args[1]))\n",
            "  File \"/content/IGMC/util_functions.py\", line 217, in subgraph_extraction_labeling\n",
            "    v_fringe, u_fringe = neighbors(u_fringe, Arow), neighbors(v_fringe, Acol)\n",
            "  File \"/content/IGMC/util_functions.py\", line 302, in neighbors\n",
            "    return set(A[list(fringe)].indices)\n",
            "  File \"/content/IGMC/util_functions.py\", line 61, in __getitem__\n",
            "    indices = np.concatenate(self.indices[col_selector])\n",
            "  File \"<__array_function__ internals>\", line 6, in concatenate\n",
            "ValueError: need at least one array to concatenate\n",
            "\"\"\"\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"Main.py\", line 338, in <module>\n",
            "    max_num=args.max_train_num\n",
            "  File \"/content/IGMC/util_functions.py\", line 91, in __init__\n",
            "    super(MyDataset, self).__init__(root)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_geometric/data/in_memory_dataset.py\", line 53, in __init__\n",
            "    pre_filter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataset.py\", line 93, in __init__\n",
            "    self._process()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch_geometric/data/dataset.py\", line 166, in _process\n",
            "    self.process()\n",
            "  File \"/content/IGMC/util_functions.py\", line 106, in process\n",
            "    self.class_values, self.parallel)\n",
            "  File \"/content/IGMC/util_functions.py\", line 190, in links2subgraphs\n",
            "    results = results.get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 657, in get\n",
            "    raise self._value\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
            "    result = (True, func(*args, **kwds))\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 47, in starmapstar\n",
            "    return list(itertools.starmap(args[0], args[1]))\n",
            "  File \"/content/IGMC/util_functions.py\", line 217, in subgraph_extraction_labeling\n",
            "    v_fringe, u_fringe = neighbors(u_fringe, Arow), neighbors(v_fringe, Acol)\n",
            "  File \"/content/IGMC/util_functions.py\", line 302, in neighbors\n",
            "    return set(A[list(fringe)].indices)\n",
            "  File \"/content/IGMC/util_functions.py\", line 61, in __getitem__\n",
            "    indices = np.concatenate(self.indices[col_selector])\n",
            "  File \"<__array_function__ internals>\", line 6, in concatenate\n",
            "ValueError: need at least one array to concatenate\n",
            "100% 16/16 [00:02<00:00,  7.14it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMPj2r7TB1xr"
      },
      "source": [
        "## t2m10 (IGMC with Max Pooling with graph norm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "dPzlDiqP-kkc",
        "outputId": "0af5ac4f-e730-4fe3-8b87-76916ead7656"
      },
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "!python Main.py --data-name amazon_fashion --epochs 40 --testing --ensemble --model-type MaxPoolIGMC --use-graphnorm --fname t2m10\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Namespace(ARR=0.001, adj_dropout=0.2, batch_size=50, continue_from=None, data_appendix='', data_name='amazon_fashion', data_seed=1234, debug=False, dynamic_test=False, dynamic_train=False, dynamic_val=False, ensemble=True, epochs=40, fname='t2m10', force_undirected=False, gconv_type='GCNConv', hop=1, keep_old=False, lr=0.001, lr_decay_factor=0.1, lr_decay_step_size=50, max_nodes_per_hop=10000, max_test_num=None, max_train_num=None, max_val_num=None, model_type='MaxPoolIGMC', multiply_by=1, no_train=False, num_relations=5, ratio=1.0, reprocess=False, sample_ratio=1.0, save_appendix='', save_interval=10, seed=1, standard_rating=False, test_freq=1, testing=True, transfer='', use_features=False, use_graphnorm=True, visualize=False)\n",
            "Command line input: python Main.py --data-name amazon_fashion --epochs 40 --testing --ensemble --model-type MaxPoolIGMC --use-graphnorm --fname t2m10\n",
            " is saved.\n",
            "raw_data/amazon_fashion/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x55e7ec41a000 @  0x7f9c828691e7 0x7f9c7ff2346e 0x7f9c7ff73c7b 0x7f9c7ff7435f 0x7f9c80016103 0x55e7e6a520e4 0x55e7e6a51de0 0x55e7e6ac66f5 0x55e7e6ac0b0e 0x55e7e6992eb0 0x7f9be95920a4 0x55e7e6a53d1d 0x55e7e6a522ff 0x55e7e6a54f6e 0x7f9c7ff7286c 0x7f9c7ff75a93 0x7f9c7ff760bc 0x7f9c7ff76cbb 0x7f9c7ff7707b 0x7f9c80018761 0x55e7e6a520e4 0x55e7e6a51de0 0x55e7e6ac66f5 0x55e7e6ac0b0e 0x55e7e6a5377a 0x55e7e6ac5e50 0x55e7e6a5369a 0x55e7e6ac1a45 0x55e7e6ac0e0d 0x55e7e6a5377a 0x55e7e6ac1a45\n",
            "raw_data/amazon_fashion/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x55e7ec398000 @  0x7f9c828691e7 0x7f9c7ff2346e 0x7f9c7ff73c7b 0x7f9c7ff7435f 0x7f9c80016103 0x55e7e6a520e4 0x55e7e6a51de0 0x55e7e6ac66f5 0x55e7e6ac0b0e 0x55e7e6992eb0 0x7f9be95920a4 0x55e7e6a53d1d 0x55e7e6a522ff 0x55e7e6a54f6e 0x7f9c7ff7286c 0x7f9c7ff75a93 0x7f9c7ff760bc 0x7f9c7ff76cbb 0x7f9c7ff7707b 0x7f9c80018761 0x55e7e6a520e4 0x55e7e6a51de0 0x55e7e6ac66f5 0x55e7e6ac0b0e 0x55e7e6a5377a 0x55e7e6ac5e50 0x55e7e6a5369a 0x55e7e6ac1a45 0x55e7e6ac0e0d 0x55e7e6a5377a 0x55e7e6ac1a45\n",
            "raw_data/amazon_fashion/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x55e7ec398000 @  0x7f9c828691e7 0x7f9c7ff2346e 0x7f9c7ff73c7b 0x7f9c7ff7435f 0x7f9c80016103 0x55e7e6a520e4 0x55e7e6a51de0 0x55e7e6ac66f5 0x55e7e6ac0b0e 0x55e7e6992eb0 0x7f9be95920a4 0x55e7e6a53d1d 0x55e7e6a522ff 0x55e7e6a54f6e 0x7f9c7ff7286c 0x7f9c7ff75a93 0x7f9c7ff760bc 0x7f9c7ff76cbb 0x7f9c7ff7707b 0x7f9c80018761 0x55e7e6a520e4 0x55e7e6a51de0 0x55e7e6ac66f5 0x55e7e6ac0b0e 0x55e7e6a5377a 0x55e7e6ac5e50 0x55e7e6a5369a 0x55e7e6ac1a45 0x55e7e6ac0e0d 0x55e7e6a5377a 0x55e7e6ac1a45\n",
            "number of users =  16566\n",
            "number of item =  11797\n",
            "All ratings are:\n",
            "[1. 2. 3. 4. 5.]\n",
            "#train: 116224, #val: 23245, #test: 29068\n",
            "Used #train graphs: 116224, #test graphs: 29068\n",
            "Total number of parameters is 31474\n",
            "Epoch 1, batch loss: 0.4811527132987976: 100% 2325/2325 [01:09<00:00, 33.67it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 78.62it/s]\n",
            "Epoch 1, train loss 0.786078, test rmse 0.592648\n",
            "Epoch 2, batch loss: 0.3102685213088989: 100% 2325/2325 [01:10<00:00, 33.01it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.79it/s]\n",
            "Epoch 2, train loss 0.581109, test rmse 0.575153\n",
            "Epoch 3, batch loss: 0.27800440788269043: 100% 2325/2325 [01:10<00:00, 32.87it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.40it/s]\n",
            "Epoch 3, train loss 0.485501, test rmse 0.567203\n",
            "Epoch 4, batch loss: 0.20760135352611542: 100% 2325/2325 [01:10<00:00, 33.11it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.71it/s]\n",
            "Epoch 4, train loss 0.421010, test rmse 0.570119\n",
            "Epoch 5, batch loss: 0.6747021675109863: 100% 2325/2325 [01:09<00:00, 33.26it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.68it/s]\n",
            "Epoch 5, train loss 0.381113, test rmse 0.567353\n",
            "Epoch 6, batch loss: 0.379264235496521: 100% 2325/2325 [01:10<00:00, 33.17it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.71it/s]\n",
            "Epoch 6, train loss 0.358725, test rmse 0.575963\n",
            "Epoch 7, batch loss: 0.2368488609790802: 100% 2325/2325 [01:09<00:00, 33.62it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.41it/s]\n",
            "Epoch 7, train loss 0.346404, test rmse 0.568539\n",
            "Epoch 8, batch loss: 0.3322356343269348: 100% 2325/2325 [01:10<00:00, 33.05it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.41it/s]\n",
            "Epoch 8, train loss 0.339054, test rmse 0.571915\n",
            "Epoch 9, batch loss: 0.18927322328090668: 100% 2325/2325 [01:09<00:00, 33.45it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.47it/s]\n",
            "Epoch 9, train loss 0.335791, test rmse 0.565115\n",
            "Epoch 10, batch loss: 0.351065456867218: 100% 2325/2325 [01:09<00:00, 33.60it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 78.72it/s]\n",
            "Epoch 10, train loss 0.334692, test rmse 0.567920\n",
            "Saving model states...\n",
            "Epoch 11, batch loss: 0.516007661819458: 100% 2325/2325 [01:09<00:00, 33.49it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 78.97it/s]\n",
            "Epoch 11, train loss 0.333050, test rmse 0.561745\n",
            "Epoch 12, batch loss: 0.2725064754486084: 100% 2325/2325 [01:09<00:00, 33.29it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 78.49it/s]\n",
            "Epoch 12, train loss 0.333258, test rmse 0.565531\n",
            "Epoch 13, batch loss: 0.10734342038631439: 100% 2325/2325 [01:10<00:00, 33.12it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.62it/s]\n",
            "Epoch 13, train loss 0.333764, test rmse 0.563335\n",
            "Epoch 14, batch loss: 0.2943946123123169: 100% 2325/2325 [01:09<00:00, 33.58it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 78.81it/s]\n",
            "Epoch 14, train loss 0.331111, test rmse 0.564848\n",
            "Epoch 15, batch loss: 0.13447076082229614: 100% 2325/2325 [01:10<00:00, 33.20it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 77.12it/s]\n",
            "Epoch 15, train loss 0.328757, test rmse 0.561502\n",
            "Epoch 16, batch loss: 0.18468764424324036: 100% 2325/2325 [01:10<00:00, 33.16it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.01it/s]\n",
            "Epoch 16, train loss 0.330603, test rmse 0.563818\n",
            "Epoch 17, batch loss: 0.14282332360744476: 100% 2325/2325 [01:09<00:00, 33.59it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.08it/s]\n",
            "Epoch 17, train loss 0.331268, test rmse 0.577670\n",
            "Epoch 18, batch loss: 0.5216706991195679: 100% 2325/2325 [01:09<00:00, 33.35it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.42it/s]\n",
            "Epoch 18, train loss 0.330297, test rmse 0.563799\n",
            "Epoch 19, batch loss: 0.1587769240140915: 100% 2325/2325 [01:08<00:00, 33.95it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 78.90it/s]\n",
            "Epoch 19, train loss 0.330716, test rmse 0.563273\n",
            "Epoch 20, batch loss: 0.3175019919872284: 100% 2325/2325 [01:09<00:00, 33.48it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 78.73it/s]\n",
            "Epoch 20, train loss 0.330853, test rmse 0.562662\n",
            "Saving model states...\n",
            "Epoch 21, batch loss: 0.8535991907119751: 100% 2325/2325 [01:09<00:00, 33.52it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 75.68it/s]\n",
            "Epoch 21, train loss 0.331015, test rmse 0.569426\n",
            "Epoch 22, batch loss: 0.789898157119751: 100% 2325/2325 [01:08<00:00, 33.80it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.81it/s]\n",
            "Epoch 22, train loss 0.330950, test rmse 0.575540\n",
            "Epoch 23, batch loss: 0.21207647025585175: 100% 2325/2325 [01:09<00:00, 33.56it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 79.32it/s]\n",
            "Epoch 23, train loss 0.329561, test rmse 0.574612\n",
            "Epoch 24, batch loss: 0.10041898488998413: 100% 2325/2325 [01:09<00:00, 33.59it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.49it/s]\n",
            "Epoch 24, train loss 0.329526, test rmse 0.564582\n",
            "Epoch 25, batch loss: 0.1640005260705948: 100% 2325/2325 [01:08<00:00, 34.19it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.85it/s]\n",
            "Epoch 25, train loss 0.328528, test rmse 0.564978\n",
            "Epoch 26, batch loss: 0.16760079562664032: 100% 2325/2325 [01:08<00:00, 33.97it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.85it/s]\n",
            "Epoch 26, train loss 0.328079, test rmse 0.563201\n",
            "Epoch 27, batch loss: 0.36033710837364197: 100% 2325/2325 [01:09<00:00, 33.52it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.25it/s]\n",
            "Epoch 27, train loss 0.327950, test rmse 0.565048\n",
            "Epoch 28, batch loss: 0.3275689482688904: 100% 2325/2325 [01:09<00:00, 33.54it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.96it/s]\n",
            "Epoch 28, train loss 0.327602, test rmse 0.560207\n",
            "Epoch 29, batch loss: 0.3800278604030609: 100% 2325/2325 [01:08<00:00, 34.04it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.56it/s]\n",
            "Epoch 29, train loss 0.328946, test rmse 0.561070\n",
            "Epoch 30, batch loss: 0.4170033633708954: 100% 2325/2325 [01:08<00:00, 34.08it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.01it/s]\n",
            "Epoch 30, train loss 0.326987, test rmse 0.564620\n",
            "Saving model states...\n",
            "Epoch 31, batch loss: 0.5758795738220215: 100% 2325/2325 [01:08<00:00, 33.98it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.63it/s]\n",
            "Epoch 31, train loss 0.326328, test rmse 0.562840\n",
            "Epoch 32, batch loss: 0.7372786402702332: 100% 2325/2325 [01:07<00:00, 34.34it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.19it/s]\n",
            "Epoch 32, train loss 0.326323, test rmse 0.563144\n",
            "Epoch 33, batch loss: 0.5982143878936768: 100% 2325/2325 [01:08<00:00, 33.74it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.19it/s]\n",
            "Epoch 33, train loss 0.326933, test rmse 0.563288\n",
            "Epoch 34, batch loss: 0.26158806681632996: 100% 2325/2325 [01:08<00:00, 34.09it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 80.12it/s]\n",
            "Epoch 34, train loss 0.325712, test rmse 0.563700\n",
            "Epoch 35, batch loss: 0.17149841785430908: 100% 2325/2325 [01:08<00:00, 33.78it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 83.13it/s]\n",
            "Epoch 35, train loss 0.326854, test rmse 0.562283\n",
            "Epoch 36, batch loss: 0.0715097114443779: 100% 2325/2325 [01:08<00:00, 34.04it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.02it/s]\n",
            "Epoch 36, train loss 0.325982, test rmse 0.562924\n",
            "Epoch 37, batch loss: 0.3019797205924988: 100% 2325/2325 [01:08<00:00, 33.87it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.06it/s]\n",
            "Epoch 37, train loss 0.327170, test rmse 0.566077\n",
            "Epoch 38, batch loss: 0.25136667490005493: 100% 2325/2325 [01:08<00:00, 34.01it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.00it/s]\n",
            "Epoch 38, train loss 0.326100, test rmse 0.571438\n",
            "Epoch 39, batch loss: 0.283083975315094: 100% 2325/2325 [01:09<00:00, 33.63it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 82.77it/s]\n",
            "Epoch 39, train loss 0.325901, test rmse 0.567286\n",
            "Epoch 40, batch loss: 0.3086332380771637: 100% 2325/2325 [01:08<00:00, 34.14it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:07<00:00, 81.55it/s]\n",
            "Epoch 40, train loss 0.325963, test rmse 0.567135\n",
            "Saving model states...\n",
            "Final Test RMSE: 0.567135, Duration: 3057.041797\n",
            "Testing begins...\n",
            "100% 582/582 [00:09<00:00, 63.92it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:09<00:00, 64.17it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:09<00:00, 64.06it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:09<00:00, 64.32it/s]\n",
            "Test Once RMSE: 0.560968, Duration: 36.326488\n",
            "Ensemble test rmse is: 0.560968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OURGrBryukS",
        "outputId": "cec4711b-9420-4ee0-ecac-5529727621f2"
      },
      "source": [
        "# t3m10\n",
        "!python Main.py --data-name ml_100k --epochs 40 --testing --ensemble --model-type MaxPoolIGMC --dynamic-train --use-graphnorm --fname t3m10 \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(ARR=0.001, adj_dropout=0.2, batch_size=50, continue_from=None, data_appendix='', data_name='ml_100k', data_seed=1234, debug=False, dynamic_test=False, dynamic_train=True, dynamic_val=False, ensemble=True, epochs=40, fname='t3m10', force_undirected=False, gconv_type='GCNConv', hop=1, keep_old=False, lr=0.001, lr_decay_factor=0.1, lr_decay_step_size=50, max_nodes_per_hop=10000, max_test_num=None, max_train_num=None, max_val_num=None, model_type='MaxPoolIGMC', multiply_by=1, no_train=False, num_relations=5, ratio=1.0, reprocess=False, sample_ratio=1.0, save_appendix='', save_interval=10, seed=1, standard_rating=False, test_freq=1, testing=True, transfer='', use_features=False, use_graphnorm=True, visualize=False)\n",
            "Command line input: python Main.py --data-name ml_100k --epochs 40 --testing --ensemble --model-type MaxPoolIGMC --dynamic-train --use-graphnorm --fname t3m10\n",
            " is saved.\n",
            "Using official MovieLens split u1.base/u1.test with 20% validation...\n",
            "User features shape: (943, 23)\n",
            "Item features shape: (1682, 18)\n",
            "All ratings are:\n",
            "[1. 2. 3. 4. 5.]\n",
            "#train: 80000, #val: 16000, #test: 20000\n",
            "tcmalloc: large alloc 2441805824 bytes == 0x55fa1dc0a000 @  0x7f62f04c3b6b 0x7f62f04e3379 0x7f62823feb4a 0x7f62824005fa 0x7f6284b04c44 0x7f62cd5d7770 0x55fa0fa74c25 0x55fa0fa357f2 0x55fa0faa8d75 0x55fa0faa3e0d 0x55fa0fa3638b 0x55fa0fa35e99 0x55fa0fb7d70d 0x55fa0faec57b 0x55fa0fa34f41 0x55fa0fb2699d 0x55fa0faa8fe9 0x55fa0faa3e0d 0x55fa0f975e2b 0x55fa0faa61e6 0x55fa0faa3b0e 0x55fa0fa3677a 0x55fa0faa8e50 0x55fa0faa3e0d 0x55fa0fa3702c 0x55fa0fa77d39 0x55fa0fa74c84 0x55fa0fa358e9 0x55fa0faa9ade 0x55fa0faa3b0e 0x55fa0faa3813\n",
            "tcmalloc: large alloc 1220902912 bytes == 0x55faaf4ba000 @  0x7f62f04c3b6b 0x7f62f04e3379 0x7f62823feb4a 0x7f62824005fa 0x7f6284b04c44 0x7f62cd5d7770 0x55fa0fa74c25 0x55fa0fa357f2 0x55fa0faa8d75 0x55fa0faa3e0d 0x55fa0fa3638b 0x55fa0fa35e99 0x55fa0fb7d70d 0x55fa0faec57b 0x55fa0fa34f41 0x55fa0fb2699d 0x55fa0faa8fe9 0x55fa0faa3e0d 0x55fa0f975e2b 0x55fa0faa61e6 0x55fa0faa3b0e 0x55fa0fa3677a 0x55fa0faa8e50 0x55fa0faa3e0d 0x55fa0fa3702c 0x55fa0fa77d39 0x55fa0fa74c84 0x55fa0fa358e9 0x55fa0faa9ade 0x55fa0faa3b0e 0x55fa0faa3813\n",
            "Used #train graphs: 80000, #test graphs: 20000\n",
            "Total number of parameters is 31474\n",
            "Epoch 5, train loss 0.956557, test rmse 0.939661:  12% 5/40 [50:03<5:50:32, 600.93s/it]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEqWyt3sOCam"
      },
      "source": [
        "!mv /content/IGMC/results/ml_100k_testmode /content/IGMC/results/t3m10 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG4zMGDVE-Kk"
      },
      "source": [
        "## 1l00 (IGMC with LSTM Attention)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "aUtwvf7AB0pk",
        "outputId": "9fe2ef54-f0ab-4778-fc3e-33d6ccf7134f"
      },
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "!python Main.py --data-name flixster --epochs 40 --testing --ensemble --model-type LSTMAttentionIGMC --fname 1l00"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Namespace(ARR=0.001, adj_dropout=0.2, batch_size=50, continue_from=None, data_appendix='', data_name='flixster', data_seed=1234, debug=False, dynamic_test=False, dynamic_train=False, dynamic_val=False, ensemble=True, epochs=40, fname='1l00', force_undirected=False, gconv_type='GCNConv', hop=1, keep_old=False, lr=0.001, lr_decay_factor=0.1, lr_decay_step_size=50, max_nodes_per_hop=10000, max_test_num=None, max_train_num=None, max_val_num=None, model_type='LSTMAttentionIGMC', multiply_by=1, no_train=False, num_relations=5, ratio=1.0, reprocess=False, sample_ratio=1.0, save_appendix='', save_interval=10, seed=1, standard_rating=False, test_freq=1, testing=True, transfer='', use_features=False, use_graphnorm=False, visualize=False)\n",
            "Command line input: python Main.py --data-name flixster --epochs 40 --testing --ensemble --model-type LSTMAttentionIGMC --fname 1l00\n",
            " is saved.\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "number of users =  2341\n",
            "number of item =  2956\n",
            "User features shape: (3000, 3000)\n",
            "Item features shape: (3000, 3000)\n",
            "All ratings are:\n",
            "[0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5. ]\n",
            "#train: 23556, #val: 4712, #test: 2617\n",
            "Used #train graphs: 23556, #test graphs: 2617\n",
            "Total number of parameters is 55746\n",
            "Epoch 10, train loss 0.892043, test rmse 0.875040:  22% 9/40 [01:31<04:44,  9.18s/it]Saving model states...\n",
            "Epoch 20, train loss 0.802353, test rmse 0.872402:  48% 19/40 [03:02<03:11,  9.14s/it]Saving model states...\n",
            "Epoch 30, train loss 0.765890, test rmse 0.873972:  72% 29/40 [04:34<01:40,  9.12s/it]Saving model states...\n",
            "Epoch 40, train loss 0.755618, test rmse 0.875480:  98% 39/40 [06:06<00:09,  9.17s/it]Saving model states...\n",
            "Epoch 40, train loss 0.755618, test rmse 0.875480: 100% 40/40 [06:06<00:00,  9.16s/it]\n",
            "Final Test RMSE: 0.875480, Duration: 366.358072\n",
            "Testing begins...\n",
            "100% 53/53 [00:00<00:00, 125.02it/s]\n",
            "Testing begins...\n",
            "100% 53/53 [00:00<00:00, 123.24it/s]\n",
            "Testing begins...\n",
            "100% 53/53 [00:00<00:00, 116.77it/s]\n",
            "Testing begins...\n",
            "100% 53/53 [00:00<00:00, 126.53it/s]\n",
            "Test Once RMSE: 0.872536, Duration: 1.731974\n",
            "Ensemble test rmse is: 0.872536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFB-kd7XIVeN"
      },
      "source": [
        "## 1l10 (IGMC with LSTM Attention with GraphNorm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "LjnIEIHLFCHu",
        "outputId": "456afc7a-1a91-4684-81c8-eb2f9ff4e6e0"
      },
      "source": [
        "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n",
        "\n",
        "!python Main.py --data-name flixster --epochs 40 --testing --ensemble --model-type LSTMAttentionIGMC --use-graphnorm --fname 1l10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "google.colab.output.setIframeHeight(0, true, {maxHeight: 300})"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Namespace(ARR=0.001, adj_dropout=0.2, batch_size=50, continue_from=None, data_appendix='', data_name='flixster', data_seed=1234, debug=False, dynamic_test=False, dynamic_train=False, dynamic_val=False, ensemble=True, epochs=40, fname='1l10', force_undirected=False, gconv_type='GCNConv', hop=1, keep_old=False, lr=0.001, lr_decay_factor=0.1, lr_decay_step_size=50, max_nodes_per_hop=10000, max_test_num=None, max_train_num=None, max_val_num=None, model_type='LSTMAttentionIGMC', multiply_by=1, no_train=False, num_relations=5, ratio=1.0, reprocess=False, sample_ratio=1.0, save_appendix='', save_interval=10, seed=1, standard_rating=False, test_freq=1, testing=True, transfer='', use_features=False, use_graphnorm=True, visualize=False)\n",
            "Command line input: python Main.py --data-name flixster --epochs 40 --testing --ensemble --model-type LSTMAttentionIGMC --use-graphnorm --fname 1l10\n",
            " is saved.\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "raw_data/flixster/training_test_dataset.mat\n",
            "number of users =  2341\n",
            "number of item =  2956\n",
            "User features shape: (3000, 3000)\n",
            "Item features shape: (3000, 3000)\n",
            "All ratings are:\n",
            "[0.5 1.  1.5 2.  2.5 3.  3.5 4.  4.5 5. ]\n",
            "#train: 23556, #val: 4712, #test: 2617\n",
            "Used #train graphs: 23556, #test graphs: 2617\n",
            "Total number of parameters is 56130\n",
            "Epoch 10, train loss 0.870346, test rmse 0.873206:  22% 9/40 [02:05<06:27, 12.51s/it]Saving model states...\n",
            "Epoch 20, train loss 0.792793, test rmse 0.870763:  48% 19/40 [04:10<04:23, 12.54s/it]Saving model states...\n",
            "Epoch 30, train loss 0.753118, test rmse 0.872370:  72% 29/40 [06:15<02:17, 12.49s/it]Saving model states...\n",
            "Epoch 40, train loss 0.739600, test rmse 0.874904:  98% 39/40 [08:20<00:12, 12.54s/it]Saving model states...\n",
            "Epoch 40, train loss 0.739600, test rmse 0.874904: 100% 40/40 [08:20<00:00, 12.50s/it]\n",
            "Final Test RMSE: 0.874904, Duration: 500.144369\n",
            "Testing begins...\n",
            "100% 53/53 [00:00<00:00, 85.82it/s]\n",
            "Testing begins...\n",
            "100% 53/53 [00:00<00:00, 84.38it/s]\n",
            "Testing begins...\n",
            "100% 53/53 [00:00<00:00, 84.17it/s]\n",
            "Testing begins...\n",
            "100% 53/53 [00:00<00:00, 85.33it/s]\n",
            "Test Once RMSE: 0.869970, Duration: 2.501714\n",
            "Ensemble test rmse is: 0.869970\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9FgcTwwZQol"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36y45lKkIcbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44e0866-6c6f-45e7-f0a4-4d6f7472e336"
      },
      "source": [
        "!python Main.py --data-name amazon_music --epochs 40 --testing --no-train --ensemble --transfer results/t3c00 --dynamic-train --num-relations 5 --multiply-by 1 --fname t3c00"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(ARR=0.001, adj_dropout=0.2, batch_size=50, continue_from=None, data_appendix='', data_name='amazon_music', data_seed=1234, debug=False, dynamic_test=False, dynamic_train=True, dynamic_val=False, ensemble=True, epochs=40, fname='t3c00', force_undirected=False, gconv_type='GCNConv', hop=1, keep_old=False, lr=0.001, lr_decay_factor=0.1, lr_decay_step_size=50, max_nodes_per_hop=10000, max_test_num=None, max_train_num=None, max_val_num=None, model_type='IGMC', multiply_by=1, no_train=True, num_relations=5, ratio=1.0, reprocess=False, sample_ratio=1.0, save_appendix='', save_interval=10, seed=1, standard_rating=False, test_freq=1, testing=True, transfer='results/t3c00', use_features=False, use_graphnorm=False, visualize=False)\n",
            "Command line input: python Main.py --data-name amazon_music --epochs 40 --testing --no-train --ensemble --transfer results/t3c00 --dynamic-train --num-relations 5 --multiply-by 1 --fname t3c00\n",
            " is saved.\n",
            "raw_data/amazon_music/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x561879816000 @  0x7fc2ba8b31e7 0x7fc2b7f6d46e 0x7fc2b7fbdc7b 0x7fc2b7fbe35f 0x7fc2b8060103 0x561873b910e4 0x561873b90de0 0x561873c056f5 0x561873bffb0e 0x561873ad1eb0 0x7fc2215dc0a4 0x561873b92d1d 0x561873b912ff 0x561873b93f6e 0x7fc2b7fbc86c 0x7fc2b7fbfa93 0x7fc2b7fc00bc 0x7fc2b7fc0cbb 0x7fc2b7fc107b 0x7fc2b8062761 0x561873b910e4 0x561873b90de0 0x561873c056f5 0x561873bffb0e 0x561873b9277a 0x561873c04e50 0x561873b9269a 0x561873c00a45 0x561873bffe0d 0x561873b9277a 0x561873c00a45\n",
            "raw_data/amazon_music/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x561879816000 @  0x7fc2ba8b31e7 0x7fc2b7f6d46e 0x7fc2b7fbdc7b 0x7fc2b7fbe35f 0x7fc2b8060103 0x561873b910e4 0x561873b90de0 0x561873c056f5 0x561873bffb0e 0x561873ad1eb0 0x7fc2215dc0a4 0x561873b92d1d 0x561873b912ff 0x561873b93f6e 0x7fc2b7fbc86c 0x7fc2b7fbfa93 0x7fc2b7fc00bc 0x7fc2b7fc0cbb 0x7fc2b7fc107b 0x7fc2b8062761 0x561873b910e4 0x561873b90de0 0x561873c056f5 0x561873bffb0e 0x561873b9277a 0x561873c04e50 0x561873b9269a 0x561873c00a45 0x561873bffe0d 0x561873b9277a 0x561873c00a45\n",
            "raw_data/amazon_music/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x561879816000 @  0x7fc2ba8b31e7 0x7fc2b7f6d46e 0x7fc2b7fbdc7b 0x7fc2b7fbe35f 0x7fc2b8060103 0x561873b910e4 0x561873b90de0 0x561873c056f5 0x561873bffb0e 0x561873ad1eb0 0x7fc2215dc0a4 0x561873b92d1d 0x561873b912ff 0x561873b93f6e 0x7fc2b7fbc86c 0x7fc2b7fbfa93 0x7fc2b7fc00bc 0x7fc2b7fc0cbb 0x7fc2b7fc107b 0x7fc2b8062761 0x561873b910e4 0x561873b90de0 0x561873c056f5 0x561873bffb0e 0x561873b9277a 0x561873c04e50 0x561873b9269a 0x561873c00a45 0x561873bffe0d 0x561873b9277a 0x561873c00a45\n",
            "number of users =  16566\n",
            "number of item =  11797\n",
            "All ratings are:\n",
            "[1. 2. 3. 4. 5.]\n",
            "#train: 116224, #val: 23245, #test: 29068\n",
            "Processing...\n",
            "Enclosing subgraph extraction begins...\n",
            " 94% 15/16 [00:14<00:00,  1.04it/s]\n",
            "Time elapsed for subgraph extraction: 14.79711103439331s\n",
            "Transforming to pytorch_geometric graphs...\n",
            "100% 29068/29068 [00:02<00:00, 14479.15it/s]\n",
            "Time elapsed for transforming to pytorch_geometric graphs: 2.0080888271331787s\n",
            "Done!\n",
            "Used #train graphs: 116224, #test graphs: 29068\n",
            "Total number of parameters is 55666\n",
            "Testing begins...\n",
            "100% 582/582 [00:04<00:00, 129.03it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:04<00:00, 128.48it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:04<00:00, 128.86it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:04<00:00, 130.97it/s]\n",
            "Test Once RMSE: 0.750195, Duration: 18.016643\n",
            "Ensemble test rmse is: 0.750195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi0Iv1vAZP3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8280ae2-c8da-4dc2-e571-4f8978dd662e"
      },
      "source": [
        "!python Main.py --data-name amazon_music --epochs 40 --testing --no-train --ensemble --transfer results/t3c10/ --use-graphnorm --dynamic-train --num-relations 5 --multiply-by 1 --fname t3c10"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(ARR=0.001, adj_dropout=0.2, batch_size=50, continue_from=None, data_appendix='', data_name='amazon_music', data_seed=1234, debug=False, dynamic_test=False, dynamic_train=True, dynamic_val=False, ensemble=True, epochs=40, fname='t3c10', force_undirected=False, gconv_type='GCNConv', hop=1, keep_old=False, lr=0.001, lr_decay_factor=0.1, lr_decay_step_size=50, max_nodes_per_hop=10000, max_test_num=None, max_train_num=None, max_val_num=None, model_type='IGMC', multiply_by=1, no_train=True, num_relations=5, ratio=1.0, reprocess=False, sample_ratio=1.0, save_appendix='', save_interval=10, seed=1, standard_rating=False, test_freq=1, testing=True, transfer='results/t3c10/', use_features=False, use_graphnorm=True, visualize=False)\n",
            "Command line input: python Main.py --data-name amazon_music --epochs 40 --testing --no-train --ensemble --transfer results/t3c10/ --use-graphnorm --dynamic-train --num-relations 5 --multiply-by 1 --fname t3c10\n",
            " is saved.\n",
            "raw_data/amazon_music/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x55bc8b564000 @  0x7f17864471e7 0x7f1783b0146e 0x7f1783b51c7b 0x7f1783b5235f 0x7f1783bf4103 0x55bc849840e4 0x55bc84983de0 0x55bc849f86f5 0x55bc849f2b0e 0x55bc848c4eb0 0x7f16ed1700a4 0x55bc84985d1d 0x55bc849842ff 0x55bc84986f6e 0x7f1783b5086c 0x7f1783b53a93 0x7f1783b540bc 0x7f1783b54cbb 0x7f1783b5507b 0x7f1783bf6761 0x55bc849840e4 0x55bc84983de0 0x55bc849f86f5 0x55bc849f2b0e 0x55bc8498577a 0x55bc849f7e50 0x55bc8498569a 0x55bc849f3a45 0x55bc849f2e0d 0x55bc8498577a 0x55bc849f3a45\n",
            "raw_data/amazon_music/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x55bc8b564000 @  0x7f17864471e7 0x7f1783b0146e 0x7f1783b51c7b 0x7f1783b5235f 0x7f1783bf4103 0x55bc849840e4 0x55bc84983de0 0x55bc849f86f5 0x55bc849f2b0e 0x55bc848c4eb0 0x7f16ed1700a4 0x55bc84985d1d 0x55bc849842ff 0x55bc84986f6e 0x7f1783b5086c 0x7f1783b53a93 0x7f1783b540bc 0x7f1783b54cbb 0x7f1783b5507b 0x7f1783bf6761 0x55bc849840e4 0x55bc84983de0 0x55bc849f86f5 0x55bc849f2b0e 0x55bc8498577a 0x55bc849f7e50 0x55bc8498569a 0x55bc849f3a45 0x55bc849f2e0d 0x55bc8498577a 0x55bc849f3a45\n",
            "raw_data/amazon_music/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x55bc8b564000 @  0x7f17864471e7 0x7f1783b0146e 0x7f1783b51c7b 0x7f1783b5235f 0x7f1783bf4103 0x55bc849840e4 0x55bc84983de0 0x55bc849f86f5 0x55bc849f2b0e 0x55bc848c4eb0 0x7f16ed1700a4 0x55bc84985d1d 0x55bc849842ff 0x55bc84986f6e 0x7f1783b5086c 0x7f1783b53a93 0x7f1783b540bc 0x7f1783b54cbb 0x7f1783b5507b 0x7f1783bf6761 0x55bc849840e4 0x55bc84983de0 0x55bc849f86f5 0x55bc849f2b0e 0x55bc8498577a 0x55bc849f7e50 0x55bc8498569a 0x55bc849f3a45 0x55bc849f2e0d 0x55bc8498577a 0x55bc849f3a45\n",
            "number of users =  16566\n",
            "number of item =  11797\n",
            "All ratings are:\n",
            "[1. 2. 3. 4. 5.]\n",
            "#train: 116224, #val: 23245, #test: 29068\n",
            "Used #train graphs: 116224, #test graphs: 29068\n",
            "Total number of parameters is 56050\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 88.97it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 88.91it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 89.32it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 87.81it/s]\n",
            "Test Once RMSE: 0.855827, Duration: 26.248943\n",
            "Ensemble test rmse is: 0.855827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1goaEzPpbh5n",
        "outputId": "5f8547ab-88f9-42d2-dc00-6c86145f0c1a"
      },
      "source": [
        "!python Main.py --data-name amazon_music --epochs 40 --testing --no-train --ensemble --transfer results/t3m10/ --dynamic-train --model-type MaxPoolIGMC --use-graphnorm  --num-relations 5 --multiply-by 1 --fname t3m10"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(ARR=0.001, adj_dropout=0.2, batch_size=50, continue_from=None, data_appendix='', data_name='amazon_music', data_seed=1234, debug=False, dynamic_test=False, dynamic_train=True, dynamic_val=False, ensemble=True, epochs=40, fname='t3m10', force_undirected=False, gconv_type='GCNConv', hop=1, keep_old=False, lr=0.001, lr_decay_factor=0.1, lr_decay_step_size=50, max_nodes_per_hop=10000, max_test_num=None, max_train_num=None, max_val_num=None, model_type='MaxPoolIGMC', multiply_by=1, no_train=True, num_relations=5, ratio=1.0, reprocess=False, sample_ratio=1.0, save_appendix='', save_interval=10, seed=1, standard_rating=False, test_freq=1, testing=True, transfer='results/t3m10/', use_features=False, use_graphnorm=True, visualize=False)\n",
            "Command line input: python Main.py --data-name amazon_music --epochs 40 --testing --no-train --ensemble --transfer results/t3m10/ --dynamic-train --model-type MaxPoolIGMC --use-graphnorm --num-relations 5 --multiply-by 1 --fname t3m10\n",
            " is saved.\n",
            "raw_data/amazon_music/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x561f7e4bc000 @  0x7f0f27f631e7 0x7f0f2561d46e 0x7f0f2566dc7b 0x7f0f2566e35f 0x7f0f25710103 0x561f771240e4 0x561f77123de0 0x561f771986f5 0x561f77192b0e 0x561f77064eb0 0x7f0e8ec8c0a4 0x561f77125d1d 0x561f771242ff 0x561f77126f6e 0x7f0f2566c86c 0x7f0f2566fa93 0x7f0f256700bc 0x7f0f25670cbb 0x7f0f2567107b 0x7f0f25712761 0x561f771240e4 0x561f77123de0 0x561f771986f5 0x561f77192b0e 0x561f7712577a 0x561f77197e50 0x561f7712569a 0x561f77193a45 0x561f77192e0d 0x561f7712577a 0x561f77193a45\n",
            "raw_data/amazon_music/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x561f7e4bc000 @  0x7f0f27f631e7 0x7f0f2561d46e 0x7f0f2566dc7b 0x7f0f2566e35f 0x7f0f25710103 0x561f771240e4 0x561f77123de0 0x561f771986f5 0x561f77192b0e 0x561f77064eb0 0x7f0e8ec8c0a4 0x561f77125d1d 0x561f771242ff 0x561f77126f6e 0x7f0f2566c86c 0x7f0f2566fa93 0x7f0f256700bc 0x7f0f25670cbb 0x7f0f2567107b 0x7f0f25712761 0x561f771240e4 0x561f77123de0 0x561f771986f5 0x561f77192b0e 0x561f7712577a 0x561f77197e50 0x561f7712569a 0x561f77193a45 0x561f77192e0d 0x561f7712577a 0x561f77193a45\n",
            "raw_data/amazon_music/training_test_dataset.mat\n",
            "tcmalloc: large alloc 1563435008 bytes == 0x561f7e4bc000 @  0x7f0f27f631e7 0x7f0f2561d46e 0x7f0f2566dc7b 0x7f0f2566e35f 0x7f0f25710103 0x561f771240e4 0x561f77123de0 0x561f771986f5 0x561f77192b0e 0x561f77064eb0 0x7f0e8ec8c0a4 0x561f77125d1d 0x561f771242ff 0x561f77126f6e 0x7f0f2566c86c 0x7f0f2566fa93 0x7f0f256700bc 0x7f0f25670cbb 0x7f0f2567107b 0x7f0f25712761 0x561f771240e4 0x561f77123de0 0x561f771986f5 0x561f77192b0e 0x561f7712577a 0x561f77197e50 0x561f7712569a 0x561f77193a45 0x561f77192e0d 0x561f7712577a 0x561f77193a45\n",
            "number of users =  16566\n",
            "number of item =  11797\n",
            "All ratings are:\n",
            "[1. 2. 3. 4. 5.]\n",
            "#train: 116224, #val: 23245, #test: 29068\n",
            "Used #train graphs: 116224, #test graphs: 29068\n",
            "Total number of parameters is 31474\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 87.74it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 88.41it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 88.29it/s]\n",
            "Testing begins...\n",
            "100% 582/582 [00:06<00:00, 88.04it/s]\n",
            "Test Once RMSE: 0.734671, Duration: 26.435003\n",
            "Ensemble test rmse is: 0.734671\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLedL1Tfg5Xw"
      },
      "source": [
        "!unzip /content/IGMC/transfer_learn_results/t2c00.zip \n",
        "!unzip /content/IGMC/transfer_learn_results/t2c10.zip \n",
        "!unzip /content/IGMC/transfer_learn_results/t2m10.zip\n",
        "!unzip /content/IGMC/transfer_learn_results/t3c00.zip \n",
        "!unzip /content/IGMC/transfer_learn_results/t3c10.zip \n",
        "!unzip /content/IGMC/transfer_learn_results/t3m10.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCPEKT6edJab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0908b3cc-8b36-4f15-8be5-82b04cb208dc"
      },
      "source": [
        "!zip -r ml_100k-flixster-transf.zip ./results/ml_100k-flixster-transf/\n",
        "!zip -r ml_100k-amazon_music-transf.zip ./results/ml_100k-amazon_music-transf/"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: results/ml_100k-flixster-transf/ (stored 0%)\n",
            "  adding: results/ml_100k-flixster-transf/t3c00-log.csv (deflated 5%)\n",
            "  adding: results/ml_100k-flixster-transf/cmd_input.txt (deflated 68%)\n",
            "  adding: results/ml_100k-flixster-transf/t3c10-tabular_results.csv (deflated 59%)\n",
            "  adding: results/ml_100k-flixster-transf/t3c00-tabular_results.csv (deflated 59%)\n",
            "  adding: results/ml_100k-flixster-transf/t3m10-tabular_results.csv (deflated 59%)\n",
            "  adding: results/ml_100k-flixster-transf/t3c10-log.csv (deflated 6%)\n",
            "  adding: results/ml_100k-flixster-transf/t3m10-log.csv (deflated 6%)\n",
            "  adding: results/ml_100k-amazon_music-transf/ (stored 0%)\n",
            "  adding: results/ml_100k-amazon_music-transf/t3c00-log.csv (deflated 5%)\n",
            "  adding: results/ml_100k-amazon_music-transf/cmd_input.txt (deflated 67%)\n",
            "  adding: results/ml_100k-amazon_music-transf/t3c10-tabular_results.csv (deflated 63%)\n",
            "  adding: results/ml_100k-amazon_music-transf/t3c00-tabular_results.csv (deflated 63%)\n",
            "  adding: results/ml_100k-amazon_music-transf/t3m10-tabular_results.csv (deflated 63%)\n",
            "  adding: results/ml_100k-amazon_music-transf/t3c10-log.csv (deflated 5%)\n",
            "  adding: results/ml_100k-amazon_music-transf/t3m10-log.csv (deflated 6%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHXVox8B_igU",
        "outputId": "45b80e0b-a30e-435f-8500-14a38564dad4"
      },
      "source": [
        "!unzip /content/IGMC/flixster-amazon_music-transf.zip\n",
        "!unzip /content/IGMC/flixster-ml_100k-transf.zip"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/IGMC/flixster-amazon_music-transf.zip\n",
            "   creating: results/flixster-amazon_music-transf/\n",
            "  inflating: results/flixster-amazon_music-transf/cmd_input.txt  \n",
            "  inflating: results/flixster-amazon_music-transf/1c10-log.csv  \n",
            "  inflating: results/flixster-amazon_music-transf/1m10-log.csv  \n",
            "  inflating: results/flixster-amazon_music-transf/1c00-log.csv  \n",
            "  inflating: results/flixster-amazon_music-transf/1c00-tabular_results.csv  \n",
            "  inflating: results/flixster-amazon_music-transf/1m10-tabular_results.csv  \n",
            "  inflating: results/flixster-amazon_music-transf/1c10-tabular_results.csv  \n",
            "Archive:  /content/IGMC/flixster-ml_100k-transf.zip\n",
            "   creating: results/flixster-ml_100k-transf/\n",
            "  inflating: results/flixster-ml_100k-transf/cmd_input.txt  \n",
            "  inflating: results/flixster-ml_100k-transf/1c10-log.csv  \n",
            "  inflating: results/flixster-ml_100k-transf/1m10-log.csv  \n",
            "  inflating: results/flixster-ml_100k-transf/1c00-log.csv  \n",
            "  inflating: results/flixster-ml_100k-transf/1c00-tabular_results.csv  \n",
            "  inflating: results/flixster-ml_100k-transf/1m10-tabular_results.csv  \n",
            "  inflating: results/flixster-ml_100k-transf/1c10-tabular_results.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q-MST8E_iiz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzMiq66j_ilM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKtYgj3LlrAH"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "results_df = pd.read_csv(\"/content/IGMC/results/flixster-ml_100k-transf/1c00-tabular_results.csv\")\n",
        "results_df2 = pd.read_csv(\"/content/IGMC/results/flixster-ml_100k-transf/1c10-tabular_results.csv\")\n",
        "results_df3 = pd.read_csv(\"/content/IGMC/results/flixster-ml_100k-transf/1m10-tabular_results.csv\")\n",
        "# results_df2 = pd.read_csv(\"results/flixster-amazon_music-transf/1m10-tabular_results.csv\")"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dwocv_oPQWEf",
        "outputId": "62115a83-5ed2-4cfa-8c03-37f3ea150c9c"
      },
      "source": [
        "results_df3.pred"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        3.902444\n",
              "1        3.083557\n",
              "2        3.208001\n",
              "3        3.622408\n",
              "4        3.598989\n",
              "           ...   \n",
              "19995    3.701535\n",
              "19996    3.870501\n",
              "19997    3.847382\n",
              "19998    3.826969\n",
              "19999    3.756484\n",
              "Name: pred, Length: 20000, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYAYbdhRg5oo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "0bc96ad7-791b-4d3f-c490-e3c8058101ff"
      },
      "source": [
        "#  c00\n",
        "plt.title('Flixster Model on ML 100K Dataset')\n",
        "plt.hist(results_df.pred, bins = 30, density=True)\n",
        "# c10\n",
        "plt.hist(results_df2.pred, bins = 30, density=True, alpha = 0.5, color = 'red')\n",
        "# m10\n",
        "plt.hist(results_df3.pred, bins = 30, density=True, alpha = 0.5, color = 'green')\n",
        "\n",
        "plt.hist(results_df.actual, bins = 20, alpha = 0.3, density=True)\n",
        "plt.legend(['Baseline', 'Graph Norm', 'Graph Norm with Max Pooling', 'Actual Rating'])\n",
        "# plt.yticks([])\n",
        "plt.ylabel('Frequency')\n",
        "plt.savefig('Flixster_Model_on_ML_100k_Ratings_Predictions_Frequency')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9OOK3tmg5mR"
      },
      "source": [
        "comb_df = results_df.merge(results_df2[['u_idx','v_idx','rmse']], on=['u_idx', 'v_idx'], suffixes=('_baseline', '_best')).groupby('actual').agg(\n",
        "    {'actual':'count', 'rmse_baseline':'mean', 'rmse_best': 'mean'}).rename({'actual': 'count'}, axis=1)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rrMZ0E9g5jS"
      },
      "source": [
        "comb_df['improvement (baseline - best)'] = comb_df['rmse_baseline'] - comb_df['rmse_best']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcoegvEfg5go",
        "outputId": "d4468d96-03be-4c0c-e5db-076690f2c165"
      },
      "source": [
        "! unzip /content/IGMC/results/amazon_music_with_flixster_to_amazon.zip \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/IGMC/results/amazon_music_with_flixster_to_amazon.zip\n",
            "   creating: results/amazon_fashion_testmode/\n",
            "  inflating: results/amazon_fashion_testmode/util_functions.py  \n",
            "  inflating: results/amazon_fashion_testmode/amazon-base-optimizer_checkpoint10.pth  \n",
            "  inflating: results/amazon_fashion_testmode/amazon-base-model_checkpoint10.pth  \n",
            "  inflating: results/amazon_fashion_testmode/Main.py  \n",
            "  inflating: results/amazon_fashion_testmode/train_eval.py  \n",
            "  inflating: results/amazon_fashion_testmode/amazon-base-model_checkpoint20.pth  \n",
            "  inflating: results/amazon_fashion_testmode/cmd_input.txt  \n",
            "  inflating: results/amazon_fashion_testmode/amazon-base-optimizer_checkpoint30.pth  \n",
            "  inflating: results/amazon_fashion_testmode/amazon-base-tabular_results.csv  \n",
            "  inflating: results/amazon_fashion_testmode/1c00-log.csv  \n",
            "  inflating: results/amazon_fashion_testmode/amazon-base-log.csv  \n",
            "  inflating: results/amazon_fashion_testmode/amazon-base-model_checkpoint40.pth  \n",
            "  inflating: results/amazon_fashion_testmode/1c00-tabular_results.csv  \n",
            "  inflating: results/amazon_fashion_testmode/amazon-base-model_checkpoint30.pth  \n",
            "  inflating: results/amazon_fashion_testmode/amazon-base-optimizer_checkpoint40.pth  \n",
            "  inflating: results/amazon_fashion_testmode/models.py  \n",
            "  inflating: results/amazon_fashion_testmode/amazon-base-optimizer_checkpoint20.pth  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6iizziKdl6-Q",
        "outputId": "b526938f-eac6-4d09-846d-b9c098c3c1b8"
      },
      "source": [
        "nos.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/IGMC'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooHAofbapm-I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}